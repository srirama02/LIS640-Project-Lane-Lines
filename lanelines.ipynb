{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "import random\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaders Set: 2510 training samples, 209 validation samples\n"
     ]
    }
   ],
   "source": [
    "train_dataset_file = '../archive/TUSimple/train_set/training/train.txt'\n",
    "val_dataset_file = '../archive/TUSimple/train_set/training/val.txt'\n",
    "\n",
    "resize_height, resize_width = 256, 512\n",
    "\n",
    "# Define the Rescale class\n",
    "class Rescale():\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (width, height) (tuple): Desired output size (width, height).\n",
    "    \"\"\"\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        # Rescale the image using OpenCV's resize function\n",
    "        sample = cv2.resize(sample, dsize=self.output_size, interpolation=cv2.INTER_NEAREST)\n",
    "        return sample\n",
    "\n",
    "# Define the TusimpleSet class\n",
    "class TusimpleSet(Dataset):\n",
    "    def __init__(self, dataset, n_labels=3, transform=None, target_transform=None):\n",
    "        self._gt_img_list = []\n",
    "        self._gt_label_binary_list = []\n",
    "        self._gt_label_instance_list = []\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.n_labels = n_labels\n",
    "\n",
    "        # Read the dataset file\n",
    "        with open(dataset, 'r') as file:\n",
    "            for _info in file:\n",
    "                info_tmp = _info.strip(' ').split()\n",
    "\n",
    "                self._gt_img_list.append(info_tmp[0])\n",
    "                self._gt_label_binary_list.append(info_tmp[1])\n",
    "                self._gt_label_instance_list.append(info_tmp[2])\n",
    "\n",
    "        assert len(self._gt_img_list) == len(self._gt_label_binary_list) == len(self._gt_label_instance_list)\n",
    "\n",
    "        # Shuffle the dataset\n",
    "        self._shuffle()\n",
    "\n",
    "        purger = 0.25\n",
    "        if purger < 1.0:\n",
    "            total_size = len(self._gt_img_list)\n",
    "            subset_size = int(total_size * purger)\n",
    "            self._gt_img_list = self._gt_img_list[:subset_size]\n",
    "            self._gt_label_binary_list = self._gt_label_binary_list[:subset_size]\n",
    "            self._gt_label_instance_list = self._gt_label_instance_list[:subset_size]\n",
    "\n",
    "    def _shuffle(self):\n",
    "        # Randomly shuffle all lists identically\n",
    "        c = list(zip(self._gt_img_list, self._gt_label_binary_list, self._gt_label_instance_list))\n",
    "        random.shuffle(c)\n",
    "        self._gt_img_list, self._gt_label_binary_list, self._gt_label_instance_list = zip(*c)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._gt_img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load images and labels\n",
    "        img = Image.open(self._gt_img_list[idx])\n",
    "        label_instance_img = cv2.imread(self._gt_label_instance_list[idx], cv2.IMREAD_UNCHANGED)\n",
    "        label_img = cv2.imread(self._gt_label_binary_list[idx], cv2.IMREAD_COLOR)\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform:\n",
    "            label_img = self.target_transform(label_img)\n",
    "            label_instance_img = self.target_transform(label_instance_img)\n",
    "\n",
    "        label_binary = np.zeros([label_img.shape[0], label_img.shape[1]], dtype=np.uint8)\n",
    "        mask = np.where((label_img[:, :, :] != [0, 0, 0]).all(axis=2))\n",
    "        label_binary[mask] = 1\n",
    "\n",
    "        return img, label_binary, label_instance_img\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((resize_height, resize_width)),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((resize_height, resize_width)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "target_transforms = transforms.Compose([\n",
    "    Rescale((resize_width, resize_height)),\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TusimpleSet(train_dataset_file, transform=data_transforms['train'], target_transform=target_transforms)\n",
    "val_dataset = TusimpleSet(val_dataset_file, transform=data_transforms['val'], target_transform=target_transforms)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Dataloaders dictionary\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader\n",
    "}\n",
    "\n",
    "# Dataset sizes\n",
    "dataset_sizes = {\n",
    "    'train': len(train_loader.dataset),\n",
    "    'val': len(val_loader.dataset)\n",
    "}\n",
    "\n",
    "print(f\"Data Loaders Set: {dataset_sizes['train']} training samples, {dataset_sizes['val']} validation samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaneNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LaneNet, self).__init__()\n",
    "        print(\"LaneNet Model Created!\")\n",
    "\n",
    "        # Encoder (Feature Extractor)\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Decoder for Binary Segmentation\n",
    "        self.deconv1_binary = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.deconv2_binary = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.deconv3_binary = nn.ConvTranspose2d(32, 2, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoding (Feature Extraction)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "\n",
    "        # Decoding (Binary Segmentation)\n",
    "        binary = self.relu(self.deconv1_binary(x))\n",
    "        binary = self.relu(self.deconv2_binary(binary))\n",
    "        binary = self.deconv3_binary(binary)\n",
    "\n",
    "        # Predicted Segmentation (Argmax for final binary output)\n",
    "        binary_pred = torch.argmax(binary, dim=1, keepdim=True)\n",
    "\n",
    "        return {\n",
    "            \"binary_seg_logits\": binary,\n",
    "            \"binary_seg_pred\": binary_pred\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "print(\"here\")\n",
    "\n",
    "def compute_loss(net_output, binary_label):\n",
    "    k_binary = 10\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    binary_seg_logits = net_output[\"binary_seg_logits\"]\n",
    "    binary_loss = loss_fn(binary_seg_logits, binary_label)\n",
    "    binary_loss = binary_loss * k_binary\n",
    "    total_loss = binary_loss\n",
    "    out = net_output[\"binary_seg_pred\"]\n",
    "    return total_loss, binary_loss, out\n",
    "\n",
    "def train_loop(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_loss_b = 0.0\n",
    "\n",
    "    for inputs, binarys, instances in dataloader:\n",
    "        inputs = inputs.float().to(device)\n",
    "        binarys = binarys.long().to(device)\n",
    "        instances = instances.float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Zero gradients\n",
    "\n",
    "        with torch.set_grad_enabled(True): \n",
    "            outputs = model(inputs)\n",
    "            total_loss, binary_loss, out = compute_loss(outputs, binarys)\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Update running loss\n",
    "        batch_size = inputs.size(0)\n",
    "        running_loss += total_loss.item() * batch_size\n",
    "        running_loss_b += binary_loss.item() * batch_size\n",
    "\n",
    "    # Step the learning rate scheduler\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    return running_loss, running_loss_b\n",
    "\n",
    "\n",
    "def test_loop(model, dataloader, device):\n",
    "    \"\"\"Evaluates the model on the validation dataset.\"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    running_loss_b = 0.0\n",
    "\n",
    "    with torch.no_grad():  # No gradients needed\n",
    "        for inputs, binarys, instances in dataloader:\n",
    "            inputs = inputs.float().to(device)\n",
    "            binarys = binarys.long().to(device)\n",
    "            instances = instances.float().to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            total_loss, binary_loss, out = compute_loss(outputs, binarys)\n",
    "\n",
    "            # Update running loss\n",
    "            batch_size = inputs.size(0)\n",
    "            running_loss += total_loss.item() * batch_size\n",
    "            running_loss_b += binary_loss.item() * batch_size\n",
    "\n",
    "    return running_loss, running_loss_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaneNet Model Created!\n",
      "Epoch 1/10\n",
      "Training Loss: 4184.3449 | Binary Loss: 4184.3449\n",
      "Validation Loss: 178.0734 | Binary Loss: 178.0734\n",
      "Saved best model weights\n",
      "Learning rate: 0.001000\n",
      "Epoch 2/10\n"
     ]
    }
   ],
   "source": [
    "# Initialize your model, optimizer, and learning rate scheduler\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming your model is defined in the previous cells\n",
    "model = LaneNet().to(device)\n",
    "\n",
    "# Define your optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define your learning rate scheduler (optional)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Assuming you have your DataLoader set up (replace with your actual DataLoader)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Set the number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Training Loop\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    # Train for one epoch\n",
    "    train_loss, train_loss_b = train_loop(model, train_dataloader, optimizer, scheduler, device)\n",
    "    print(f\"Training Loss: {train_loss:.4f} | Binary Loss: {train_loss_b:.4f}\")\n",
    "    \n",
    "    # Validate the model on the validation set\n",
    "    val_loss, val_loss_b = test_loop(model, val_dataloader, device)\n",
    "    print(f\"Validation Loss: {val_loss:.4f} | Binary Loss: {val_loss_b:.4f}\")\n",
    "\n",
    "    # Save the model if it's the best so far\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_wts, \"best_model.pth\")\n",
    "        print(\"Saved best model weights\")\n",
    "\n",
    "    # Optionally print learning rate or scheduler information\n",
    "    print(f\"Learning rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "# Load the best model weights after training\n",
    "model.load_state_dict(best_model_wts)\n",
    "print(\"Training complete. Best model loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaneNet Model Created!\n",
      "Prediction visualization completed. Check test_output directory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_test_data(img_path, transform):\n",
    "    img = Image.open(img_path)\n",
    "    img = transform(img)\n",
    "    return img\n",
    "\n",
    "def test():\n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists('test_output'):\n",
    "        os.mkdir('test_output')\n",
    "    \n",
    "    # Hardcode image parameters for testing\n",
    "    img_path = '0001.png'\n",
    "    resize_height, resize_width = 256, 512\n",
    "    model_path = 'best_model.pth'\n",
    "    \n",
    "    # Define the data transformation pipeline\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.Resize((resize_height, resize_width)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load the pre-trained model\n",
    "    model = LaneNet()\n",
    "    state_dict = torch.load(model_path)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    # Prepare the image input\n",
    "    dummy_input = load_test_data(img_path, data_transform).to(DEVICE)\n",
    "    dummy_input = torch.unsqueeze(dummy_input, dim=0)\n",
    "    \n",
    "    # Forward pass through the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(dummy_input)\n",
    "    \n",
    "    # Load original input image\n",
    "    input_img = Image.open(img_path)\n",
    "    input_img = input_img.resize((resize_width, resize_height))\n",
    "    input_img = np.array(input_img)\n",
    "    \n",
    "    # Process binary segmentation predictions\n",
    "    binary_logits = outputs['binary_seg_logits']\n",
    "    binary_pred = outputs['binary_seg_pred']\n",
    "    \n",
    "    # Convert outputs to numpy for visualization\n",
    "    binary_logits_np = binary_logits.detach().cpu().numpy()\n",
    "    binary_pred_np = binary_pred.detach().cpu().numpy()\n",
    "    \n",
    "    # Visualize and save results\n",
    "    # Original input image\n",
    "    cv2.imwrite(os.path.join('test_output', 'input.jpg'), input_img)\n",
    "    \n",
    "    # Binary segmentation logits (channel-wise)\n",
    "    for i in range(binary_logits_np.shape[1]):\n",
    "        channel_logits = binary_logits_np[0, i, :, :]\n",
    "        # Normalize to 0-255 for visualization\n",
    "        channel_logits_norm = cv2.normalize(channel_logits, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        cv2.imwrite(os.path.join('test_output', f'binary_logits_channel_{i}.jpg'), channel_logits_norm)\n",
    "    \n",
    "    # Binary prediction mask\n",
    "    binary_pred_visual = binary_pred_np[0, 0, :, :] * 255\n",
    "    cv2.imwrite(os.path.join('test_output', 'binary_prediction.jpg'), binary_pred_visual)\n",
    "    \n",
    "    # Optional: Overlay prediction on input image\n",
    "    overlay = input_img.copy()\n",
    "    overlay[binary_pred_np[0, 0, :, :] > 0] = [0, 0, 255]  # Color detected lanes red\n",
    "    cv2.imwrite(os.path.join('test_output', 'input_with_prediction_overlay.jpg'), overlay)\n",
    "    \n",
    "    print(\"Prediction visualization completed. Check test_output directory.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
