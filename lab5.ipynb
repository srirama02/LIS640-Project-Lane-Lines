{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# IMPORTANT: Move the dataset class definition to a separate file (e.g., dataset.py)\n",
    "# Or disable multiprocessing by setting num_workers=0 in DataLoader\n",
    "# The error happens because multiprocessing can't pickle the dataset class properly\n",
    "\n",
    "class LaneLineDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, transform=None, img_size=(256, 256)):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        # Get list of image files\n",
    "        self.image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))])\n",
    "        self.label_files = sorted([f for f in os.listdir(label_dir) if f.endswith('.txt')])\n",
    "        \n",
    "        # Ensure matching files\n",
    "        img_basenames = [os.path.splitext(f)[0] for f in self.image_files]\n",
    "        lbl_basenames = [os.path.splitext(f)[0] for f in self.label_files]\n",
    "        \n",
    "        common_basenames = list(set(img_basenames) & set(lbl_basenames))\n",
    "        \n",
    "        # Filter to include only files with both image and label\n",
    "        self.image_files = [f for f in self.image_files if os.path.splitext(f)[0] in common_basenames]\n",
    "        self.label_files = [os.path.splitext(f)[0] + '.txt' for f in self.image_files]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        label_path = os.path.join(self.label_dir, self.label_files[idx])\n",
    "\n",
    "        # Load and transform image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        orig_width, orig_height = image.size\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Load label (YOLO format)\n",
    "        lane_lines = []\n",
    "        with open(label_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                values = list(map(float, line.strip().split()))\n",
    "                if not values:\n",
    "                    continue\n",
    "                    \n",
    "                class_id = int(values[0])  # First value is the class\n",
    "                # Rest are polygon coordinates in normalized form [x1, y1, x2, y2, ...]\n",
    "                polygon = torch.tensor(values[1:])\n",
    "                \n",
    "                # Ensure even number of coordinates\n",
    "                if len(polygon) % 2 != 0:\n",
    "                    polygon = polygon[:-1]  # Remove last element if odd\n",
    "                \n",
    "                lane_lines.append(polygon)\n",
    "        \n",
    "        # Create lane existence indicator\n",
    "        max_lanes = 5\n",
    "        lane_exists = torch.zeros(max_lanes)\n",
    "        for i in range(min(len(lane_lines), max_lanes)):\n",
    "            lane_exists[i] = 1.0\n",
    "        \n",
    "        # Convert list of polygons to padded tensor\n",
    "        points_per_lane = 30  # 15 (x,y) pairs, more points for better curve definition\n",
    "        \n",
    "        # Create tensor filled with padding value (-1)\n",
    "        lanes_tensor = torch.ones((max_lanes, points_per_lane)) * -1\n",
    "        \n",
    "        # Fill in the actual lane data\n",
    "        for i, lane in enumerate(lane_lines):\n",
    "            if i >= max_lanes:\n",
    "                break  # Skip if more than max_lanes\n",
    "            \n",
    "            # Ensure we don't exceed points_per_lane\n",
    "            points_to_copy = min(lane.shape[0], points_per_lane)\n",
    "            lanes_tensor[i, :points_to_copy] = lane[:points_to_copy]\n",
    "        \n",
    "        return image, lanes_tensor, lane_exists\n",
    "\n",
    "# Using ResNet-like blocks for better feature extraction\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ImprovedLaneNet(nn.Module):\n",
    "    def __init__(self, max_lanes=5, points_per_lane=30):\n",
    "        super(ImprovedLaneNet, self).__init__()\n",
    "        \n",
    "        self.max_lanes = max_lanes\n",
    "        self.points_per_lane = points_per_lane\n",
    "\n",
    "        # Initial convolution\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        # Residual blocks for feature extraction\n",
    "        self.layer1 = self._make_layer(32, 64, 2)\n",
    "        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n",
    "        \n",
    "        # Lane existence prediction\n",
    "        self.exists_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, max_lanes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Lane coordinate prediction\n",
    "        self.lane_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((4, 4)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 4 * 4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, max_lanes * points_per_lane)\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, num_blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(ResidualBlock(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        \n",
    "        # Lane existence prediction\n",
    "        existence = self.exists_head(x)\n",
    "        \n",
    "        # Lane coordinate prediction\n",
    "        lanes = self.lane_head(x)\n",
    "        lanes = lanes.view(-1, self.max_lanes, self.points_per_lane)\n",
    "        \n",
    "        return lanes, existence\n",
    "\n",
    "# Combined loss function for lane detection\n",
    "class CombinedLaneLoss(nn.Module):\n",
    "    def __init__(self, existence_weight=0.5, coordinate_weight=1.0):\n",
    "        super(CombinedLaneLoss, self).__init__()\n",
    "        self.existence_weight = existence_weight\n",
    "        self.coordinate_weight = coordinate_weight\n",
    "        self.bce = nn.BCELoss()\n",
    "        self.mse = nn.MSELoss(reduction='none')\n",
    "    \n",
    "    def forward(self, pred_coords, pred_exists, target_coords, target_exists):\n",
    "        # Lane existence loss\n",
    "        existence_loss = self.bce(pred_exists, target_exists)\n",
    "        \n",
    "        # Coordinate loss with masking for both valid lanes and valid points\n",
    "        # Create a 2D mask: [batch, max_lanes, points] where lanes exist and points are valid\n",
    "        lane_mask = target_exists.unsqueeze(-1).expand_as(target_coords)\n",
    "        point_mask = (target_coords != -1).float()\n",
    "        mask = lane_mask * point_mask\n",
    "        \n",
    "        # Apply MSE loss only on valid points of valid lanes\n",
    "        coord_loss = self.mse(pred_coords, target_coords)\n",
    "        masked_loss = coord_loss * mask\n",
    "        \n",
    "        # Average over valid points\n",
    "        valid_points = mask.sum()\n",
    "        if valid_points > 0:\n",
    "            coordinate_loss = masked_loss.sum() / valid_points\n",
    "        else:\n",
    "            coordinate_loss = torch.tensor(0.0, device=pred_coords.device)\n",
    "        \n",
    "        # Combined loss\n",
    "        total_loss = (self.existence_weight * existence_loss + \n",
    "                      self.coordinate_weight * coordinate_loss)\n",
    "        \n",
    "        return total_loss, existence_loss, coordinate_loss\n",
    "\n",
    "# Custom collate function\n",
    "def custom_collate_fn(batch):\n",
    "    images = []\n",
    "    lanes = []\n",
    "    lane_exists = []\n",
    "    \n",
    "    for image, lane, exists in batch:\n",
    "        images.append(image)\n",
    "        lanes.append(lane)\n",
    "        lane_exists.append(exists)\n",
    "    \n",
    "    images = torch.stack(images)\n",
    "    lanes = torch.stack(lanes)\n",
    "    lane_exists = torch.stack(lane_exists)\n",
    "    \n",
    "    return images, lanes, lane_exists\n",
    "\n",
    "# Training function with learning rate scheduler\n",
    "def train_model(model, train_loader, val_loader, num_epochs=20):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = CombinedLaneLoss(existence_weight=0.5, coordinate_weight=1.0)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    "    )\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for images, lane_coords, lane_exists in train_loader:\n",
    "            images = images.to(device)\n",
    "            lane_coords = lane_coords.to(device)\n",
    "            lane_exists = lane_exists.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            pred_coords, pred_exists = model(images)\n",
    "            loss, exist_loss, coord_loss = criterion(pred_coords, pred_exists, lane_coords, lane_exists)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, lane_coords, lane_exists in val_loader:\n",
    "                images = images.to(device)\n",
    "                lane_coords = lane_coords.to(device)\n",
    "                lane_exists = lane_exists.to(device)\n",
    "                \n",
    "                pred_coords, pred_exists = model(images)\n",
    "                loss, exist_loss, coord_loss = criterion(pred_coords, pred_exists, lane_coords, lane_exists)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_lane_model.pth')\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}: ' \n",
    "              f'Train Loss: {train_loss:.4f}, '\n",
    "              f'Validation Loss: {val_loss:.4f}')\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Visualization functions\n",
    "def visualize_lane_predictions(model, dataloader, num_samples=5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Get samples for visualization\n",
    "    samples = []\n",
    "    with torch.no_grad():\n",
    "        for images, lane_coords, lane_exists in dataloader:\n",
    "            batch_size = images.shape[0]\n",
    "            for i in range(min(batch_size, num_samples - len(samples))):\n",
    "                samples.append((\n",
    "                    images[i].clone(),\n",
    "                    lane_coords[i].clone(),\n",
    "                    lane_exists[i].clone()\n",
    "                ))\n",
    "            if len(samples) >= num_samples:\n",
    "                break\n",
    "    \n",
    "    # Create figure for visualization\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(12, 4 * num_samples))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (image, ground_truth, gt_exists) in enumerate(samples):\n",
    "            # Get prediction\n",
    "            image_tensor = image.unsqueeze(0).to(device)\n",
    "            pred_coords, pred_exists = model(image_tensor)\n",
    "            pred_coords = pred_coords[0].cpu()\n",
    "            pred_exists = pred_exists[0].cpu()\n",
    "            \n",
    "            # Convert to numpy for visualization\n",
    "            img_np = image.permute(1, 2, 0).numpy()\n",
    "            \n",
    "            # Denormalize image for better visualization\n",
    "            mean = np.array([0.485, 0.456, 0.406])\n",
    "            std = np.array([0.229, 0.224, 0.225])\n",
    "            img_np = img_np * std + mean\n",
    "            img_np = np.clip(img_np, 0, 1)\n",
    "            \n",
    "            # Ground truth image\n",
    "            axes[i, 0].imshow(img_np)\n",
    "            axes[i, 0].set_title(\"Ground Truth\")\n",
    "            plot_lanes(axes[i, 0], ground_truth, gt_exists, img_np.shape[1], img_np.shape[0])\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            # Prediction image\n",
    "            axes[i, 1].imshow(img_np)\n",
    "            axes[i, 1].set_title(\"Prediction\")\n",
    "            plot_lanes(axes[i, 1], pred_coords, pred_exists, img_np.shape[1], img_np.shape[0])\n",
    "            axes[i, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lane_predictions.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_lanes(ax, lane_data, lane_exists, img_width, img_height):\n",
    "    colors = ['r', 'g', 'b', 'c', 'm']\n",
    "    \n",
    "    for lane_idx, lane in enumerate(lane_data):\n",
    "        # Skip invalid lanes\n",
    "        if lane_idx >= len(lane_exists) or lane_exists[lane_idx] < 0.5:\n",
    "            continue\n",
    "            \n",
    "        lane_np = lane.detach().cpu().numpy()\n",
    "        \n",
    "        points_x = []\n",
    "        points_y = []\n",
    "        \n",
    "        # Process points in pairs (x,y)\n",
    "        for j in range(0, len(lane_np), 2):\n",
    "            if j+1 < len(lane_np) and lane_np[j] != -1 and lane_np[j+1] != -1:\n",
    "                # Unnormalize coordinates\n",
    "                x = lane_np[j] * img_width\n",
    "                y = lane_np[j+1] * img_height\n",
    "                points_x.append(x)\n",
    "                points_y.append(y)\n",
    "        \n",
    "        if points_x and points_y:\n",
    "            # Plot the lane\n",
    "            ax.plot(points_x, points_y, color=colors[lane_idx % len(colors)], linewidth=3, marker='.')\n",
    "\n",
    "def main():\n",
    "    # Define transforms with data augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.RandomAffine(degrees=5, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = LaneLineDataset(\n",
    "        image_dir=\"../ComputerVisionGroup/train/images\",\n",
    "        label_dir=\"../ComputerVisionGroup/train/labels\",\n",
    "        transform=train_transform\n",
    "    )\n",
    "    \n",
    "    # Split into train and validation\n",
    "    val_size = int(0.1 * len(train_dataset))\n",
    "    train_size = len(train_dataset) - val_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "    \n",
    "    test_dataset = LaneLineDataset(\n",
    "        image_dir=\"../Maanasa/train/images\",\n",
    "        label_dir=\"../Maanasa/train/labels\",\n",
    "        transform=test_transform\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders WITH NUM_WORKERS=0 TO FIX THE ERROR\n",
    "    batch_size = 16\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        collate_fn=custom_collate_fn,\n",
    "        num_workers=0  # Changed from 2 to 0 to fix multiprocessing issue\n",
    "    )\n",
    "    \n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        collate_fn=custom_collate_fn,\n",
    "        num_workers=0  # Changed from 2 to 0\n",
    "    )\n",
    "    \n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        collate_fn=custom_collate_fn,\n",
    "        num_workers=0  # Changed from 2 to 0\n",
    "    )\n",
    "    \n",
    "    # Visualization dataloader with smaller batch size\n",
    "    test_dataloader_viz = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=1, \n",
    "        shuffle=True, \n",
    "        collate_fn=custom_collate_fn,\n",
    "        num_workers=0  # Changed from 2 to 0\n",
    "    )\n",
    "    \n",
    "    # Initialize model\n",
    "    model = ImprovedLaneNet(max_lanes=5, points_per_lane=30)\n",
    "    \n",
    "    # Train the model\n",
    "    history = train_model(\n",
    "        model, \n",
    "        train_dataloader, \n",
    "        val_dataloader, \n",
    "        num_epochs=30\n",
    "    )\n",
    "    \n",
    "    # Load best model for visualization\n",
    "    model.load_state_dict(torch.load('best_lane_model.pth'))\n",
    "    \n",
    "    # Visualize predictions\n",
    "    visualize_lane_predictions(model, test_dataloader_viz, num_samples=5)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
