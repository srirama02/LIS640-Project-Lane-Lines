{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a83ca55",
   "metadata": {},
   "source": [
    "## Milestone 1: Problem Definition, Dataset Selection, and Data Exploration\n",
    "\n",
    "LIS 640 - Introduction to Applied Deep Learning\n",
    "\n",
    "Due 2/14/25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da321fe4",
   "metadata": {},
   "source": [
    "## **Overview**\n",
    "In this milestone, you will:\n",
    "1. **Define a deep learning problem** where AI can make a meaningful impact.\n",
    "2. **Identify three datasets** that fit your topic and justify their relevance.\n",
    "3. **Explore and visualize** the datasets to understand their structure.\n",
    "4. **Implement a PyTorch Dataset class** to prepare data for deep learning.\n",
    "\n",
    "This notebook provides an example of **fuel-efficient car usage** to illustrate what is expected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba4078e",
   "metadata": {},
   "source": [
    "## **Step 1: Define Your Deep Learning Problem**\n",
    "Write a paragraph explaining:\n",
    "- **Why your chosen topic is important.**\n",
    "- **How deep learning can help solve the problem.**\n",
    "\n",
    "### **Example Problem Statement: Fuel-Efficient Car Usage**\n",
    "*Fuel efficiency is a major factor in reducing carbon emissions and lowering fuel costs. Drivers often adopt inefficient driving patterns, wasting fuel through unnecessary acceleration, braking, or idling. A deep learning model could analyze driving behavior and suggest optimizations in real-time, helping individuals improve their fuel economy.*\n",
    "\n",
    "âž¡ **Write your problem statement below:**  \n",
    "\n",
    "### **Lane Line Detection**\n",
    "Lane line detection is a crucial aspect of most autonomous driving systems. It involves identifying and tracking the lane markings on the road to ensure the vehicle stays within its designated lane. Accurate lane detection is essential for maintaining safe driving conditions, enabling features like lane-keeping assistance, adaptive cruise control, and autonomous navigation. However, challenges such as varying lighting conditions, occlusions (e.g., by other vehicles or debris), and poorly marked or faded lane lines can make this task complex. A deep learning model trained on annotated road images can be used to detect lane lines in real-time, providing the vehicle with the necessary information to make informed decisions and navigate safely. By improving the robustness and accuracy of lane detection systems, we can enhance the safety and reliability of autonomous vehicles, ultimately contributing to safer roads and more efficient transportation systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bb8cc8",
   "metadata": {},
   "source": [
    "## **Step 2: Identify and Justify Three Relevant Datasets**\n",
    "Find three datasets that provide useful information for solving your problem.  \n",
    "For each dataset, include:\n",
    "1. A **short description** of what it contains.\n",
    "2. A **link to the dataset**.\n",
    "3. **Why this dataset is useful for your problem.**\n",
    "\n",
    "### **Example Datasets for Fuel Efficiency**\n",
    "\n",
    "- **Dataset 1: Vehicle Trajectory Data (NGSIM US 101 Dataset)**\n",
    "\t- Description: This dataset contains detailed vehicle trajectory data collected on a segment of the U.S. Highway 101 in Los Angeles, California. It includes precise location information of each vehicle within the study area every one-tenth of a second, capturing detailed lane-changing and car-following behaviors.\n",
    "\t- Source: [U.S. Department of Transportation - NGSIM Program](https://data.transportation.gov/stories/s/Next-Generation-Simulation-NGSIM-Open-Data/i5zb-xe34/)\n",
    "\t- Justification: Analyzing this data can help identify driving patterns that affect fuel efficiency, such as frequent lane changes or abrupt braking.\n",
    "\n",
    "- **Dataset 2: Climate & Air Quality Data**  \n",
    "  - Description: Contains CO2 emissions and climate-related metrics across different regions.\n",
    "\tâ€¢\tSource: [U.S. Historical Climatology Network](https://www.ncei.noaa.gov/products/land-based-station/us-historical-climatology-network)\n",
    "\tâ€¢\tJustification: Can correlate driving behavior with environmental impact. Provides environmental context to fuel consumption.\n",
    "\n",
    "- **Dataset 3: Automobile Dataset (UCI Machine Learning Repository)**\n",
    "  - Description: This dataset includes various characteristics of automobiles, such as engine size, horsepower, weight, and fuel consumption. It also provides information on insurance risk ratings and normalized losses in use as compared to other cars.\n",
    "  - Source: [UCI Machine Learning Repository - Automobile Dataset](https://archive.ics.uci.edu/dataset/10/automobile)\n",
    "  - Justification: The datasetâ€™s detailed vehicle specifications and performance metrics can be used to analyze how different factors influence fuel efficiency, aiding in the development of predictive models.\n",
    "\n",
    "âž¡ **Find and document three datasets for your problem below:**\n",
    "\n",
    "- **Dataset 1: Lane Line detection Dataset**\n",
    "\t- Description: This dataset has 100 images from German roads including annotated lane lines in each image. The dataset is diverse including curved roads.\n",
    "\t- Source: [New-Lane detection Computer Vision](https://universe.roboflow.com/maanasa-prasad/new-lane-detection)\n",
    "\t- Justification: Provides lane line data from different environments and includes curved lane lines.\n",
    "\n",
    "- **Dataset 2: Indian Roads Dataset**\n",
    "\t- Description: This dataset contains over 650 labeled lane images of various road environments, such as curves, traffic, and more. It is collected from real scenarios across multiple cities in India, and includes images with lane lines that are manually annotated with polygons.\n",
    "\t- Source: Uploaded on Roboflow\n",
    "\t- Justification: Provides lane line data from a different road driving setting, allowing us to get a better variety of data (i.e. left/right hand drive, different road markings, etc).\n",
    "\n",
    "- **Dataset 3: US Roads Dataset**\n",
    "\t- Description: This dataset contains over 100 labeled lane images from highway driving in the United States in clear conditions. It includes images with the relevant lanes and lane lines annotated with polygons.\n",
    "\t- Source: Uploaded on Roboflow\n",
    "\t- Justification: Provides lane line data from a more local and potentially more relevant setting where lane line detection might be more necessary â€“ ADAS/hands-off cruise control and steering for long highway drives.\n",
    "\n",
    "\n",
    "\n",
    "### We also found these datasets, but have not analyzed them yet due to the size and might explore them later if possible\n",
    "- **Dataset 1: CurveLanes Dataset from Kaggle**\n",
    "\t- Description: This dataset has 150k lane images of difficult scenarios such as curves and multi-lanes in traffic. It is collected from real urban and highway scenarios in multiple cities in China. The dataset includes images with lane lines which are manually annotated with natural cubic splines. The labels include two key x, y coordinates of the lane marking.\n",
    "\t- Source: [Kaggle CurveLanes Dataset](https://www.kaggle.com/datasets/bnyadmohammed/curvelanes/data) and uploaded from [Github CurveLanes Dataset](https://github.com/SoulmateB/CurveLanes)\n",
    "\t- Justification: The dataset includes more difficult to detect lane lines in more complex and variety of scenarios\n",
    "\n",
    "- **Dataset 2: Waymo Open Dataset - Motion Dataset**\n",
    "\t- Description: This dataset has lane line data which was used internally by Waymo for their training purposes which has been open sourced. It includes lane connections, lane boundaries and lane neighbors. It provies information of multiple x, y coordinates along the lane line as labels.\n",
    "\t- Source [Waymo Open Dataset](https://github.com/waymo-research/waymo-open-dataset?tab=readme-ov-file)\n",
    "\t- Justification: This data includes detailed information on more lane line data but also includes features such as lane neighbors and lane connections.\n",
    "\n",
    "- **Dataset 3: TuSimple Lane Line Dataset**\n",
    "\t- Description: The dataset consists of 6,408 road images on US highways and includes images from different weather conditions. Dataset includes annotated lane lines.\n",
    "\t- Source [TuSimple Dataset on Kaggle](https://www.kaggle.com/datasets/manideep1108/tusimple)\n",
    "\t- Justification: This dataset emphasizes variation in weather conditions which the other datasets do not mention which will allow our model to generalize better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e90508",
   "metadata": {},
   "source": [
    "## **Step 3: Explore and Visualize Your Data**\n",
    "Understanding the structure of your dataset is crucial. Perform the following tasks:\n",
    "1. **Summarize dataset statistics:**\n",
    "   - Number of samples\n",
    "   - Number of features\n",
    "   - Data types (numerical, categorical, text, etc.)\n",
    "   - Ranges of values (min/max)\n",
    "   - Missing values\n",
    "\n",
    "2. **Create visualizations:**\n",
    "   - Histograms: Show feature distributions.\n",
    "   - Scatter plots: Explore relationships between key variables.\n",
    "   - (Optional) PCA: Visualize high-dimensional data in 2D.\n",
    "\n",
    "### **Example Exploration Code**\n",
    "Modify this code to work with your dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb59d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Load dataset (modify with your own file)\n",
    "# df = pd.read_csv(\"your_dataset.csv\")\n",
    "\n",
    "# # Display basic information\n",
    "# print(\"Dataset Overview:\")\n",
    "# print(df.info())\n",
    "\n",
    "# # Show summary statistics\n",
    "# print(\"Summary Statistics:\")\n",
    "# print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e7af6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Histogram of numerical features\n",
    "# df.hist(figsize=(12, 8))\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75704179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example scatter plot of two features (modify column names as needed)\n",
    "# sns.scatterplot(x=df['feature1'], y=df['feature2'])\n",
    "# plt.title(\"Feature1 vs Feature2\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ecaca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# import numpy as np\n",
    "\n",
    "# # Apply PCA for dimensionality reduction (modify as needed)\n",
    "# pca = PCA(n_components=2)\n",
    "# X_pca = pca.fit_transform(df.select_dtypes(include=[np.number]))\n",
    "\n",
    "# # Plot PCA results\n",
    "# plt.scatter(X_pca[:, 0], X_pca[:, 1])\n",
    "# plt.title(\"PCA Projection of Dataset\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44845598",
   "metadata": {},
   "source": [
    "For each figure that you create, add an explanation of why this is a useful figure. What does it tell about your data? Which figures do you find most interesting and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8d368c",
   "metadata": {},
   "source": [
    "## **Step 4: Implement a PyTorch Dataset Class**\n",
    "Follow [this tutorial](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) to prepare data for deep learning by creating a PyTorch Dataset class that:\n",
    "- Loads data from a CSV or another source.\n",
    "- Applies preprocessing (e.g., normalization, missing value handling).\n",
    "- Returns samples in a PyTorch-compatible format.\n",
    "\n",
    "### **Example PyTorch Dataset Implementation**\n",
    "Modify this template for your dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38de410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "\n",
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, csv_file):\n",
    "#         self.data = pd.read_csv(csv_file)\n",
    "#         self.features = self.data[['feature1', 'feature2']].values  # Modify features\n",
    "#         self.labels = self.data['target'].values  # Modify target\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         x = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "#         y = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "#         return x, y\n",
    "\n",
    "# # Example usage\n",
    "# dataset = CustomDataset('your_dataset.csv')\n",
    "# print(len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81b9e4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class LaneDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_dir (str): Path to the directory with images.\n",
    "            label_dir (str): Path to the directory with lane line annotations.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = sorted(os.listdir(image_dir))\n",
    "        self.label_files = sorted(os.listdir(label_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # Ensure image is in RGB format\n",
    "\n",
    "        # Load label (from the corresponding .txt file)\n",
    "        label_path = os.path.join(self.label_dir, self.label_files[idx])\n",
    "        with open(label_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            # Parse lane line annotations\n",
    "            lanes = []\n",
    "            for line in lines:\n",
    "                # Split the line into components\n",
    "                parts = list(map(float, line.strip().split()))\n",
    "                class_id = int(parts[0])  # Class ID (e.g., 0 for lane)\n",
    "                points = parts[1:]  # Lane points (x1, y1, x2, y2, ...)\n",
    "                lanes.append((class_id, points))\n",
    "\n",
    "        # Convert to numpy arrays or tensors\n",
    "        lanes = np.array(lanes)  # Shape: (num_lanes, 1 + num_points * 2)\n",
    "\n",
    "        # Apply transformations (if any)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Return image and label\n",
    "        return image, lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torchvision\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "# Example transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((360, 640)),  # Resize to a fixed size\n",
    "    transforms.ToTensor(),           # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Initialize dataset\n",
    "train_dataset = LaneDataset(\n",
    "    image_dir=\"New-Lane_detection.v1i.yolov11/train/images\",\n",
    "    label_dir=\"New-Lane_detection.v1i.yolov11/train/labels\",\n",
    "    transform=transform\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([3, 360, 640])\n",
      "Label: [(0, [0.355285625, 1.0, 0.4615511298076923, 0.5084549158653846, 0.45618570192307695, 0.5016216923076923, 0.3470609206730769, 1.0, 0.355285625, 1.0])]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "class LaneDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_dir (str): Path to the directory with images.\n",
    "            label_dir (str): Path to the directory with lane line annotations.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = sorted(os.listdir(image_dir))\n",
    "        self.label_files = sorted(os.listdir(label_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # Ensure image is in RGB format\n",
    "\n",
    "        # Load label (from the corresponding .txt file)\n",
    "        label_path = os.path.join(self.label_dir, self.label_files[idx])\n",
    "        with open(label_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            # Parse lane line annotations\n",
    "            lanes = []\n",
    "            for line in lines:\n",
    "                # Split the line into components\n",
    "                parts = list(map(float, line.strip().split()))\n",
    "                class_id = int(parts[0])  # Class ID (e.g., 0 for lane)\n",
    "                points = parts[1:]  # Lane points (x1, y1, x2, y2, ...)\n",
    "                lanes.append((class_id, points))\n",
    "\n",
    "        # Do not convert to NumPy array (keep as a list of lists)\n",
    "        # lanes = np.array(lanes)  # This line caused the error\n",
    "\n",
    "        # Apply transformations (if any)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Return image and label\n",
    "        return image, lanes\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((360, 640)),  # Resize to a fixed size\n",
    "    transforms.ToTensor(),           # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
    "])\n",
    "\n",
    "# Initialize dataset\n",
    "train_dataset = LaneDataset(\n",
    "    image_dir=\"New-Lane_detection.v1i.yolov11/train/images\",\n",
    "    label_dir=\"New-Lane_detection.v1i.yolov11/train/labels\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "\n",
    "# Example usage\n",
    "image, label = train_dataset[0]\n",
    "print(\"Image shape:\", image.shape)\n",
    "print(\"Label:\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bcf39c",
   "metadata": {},
   "source": [
    "## **Final Submission**\n",
    "Upload your submission for Milestone 1 to Canvas. \n",
    "Submit this notebook with:\n",
    "\n",
    "âœ… A **clear problem statement**.  \n",
    "âœ… Three **documented datasets** with justification.  \n",
    "âœ… **Exploratory analysis** with summary statistics & visualizations.  \n",
    "âœ… A **PyTorch Dataset class** for preparing data.  \n",
    "\n",
    "ðŸ“Œ Use the provided example to guide your work. Happy Deep Learning! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lis640",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
