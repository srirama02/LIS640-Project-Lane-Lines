{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a83ca55",
   "metadata": {},
   "source": [
    "## Milestone 2: Neural Network Baseline and Hyperparameter Optimization\n",
    "\n",
    "LIS 640 - Introduction to Applied Deep Learning\n",
    "\n",
    "Due 3/7/25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da321fe4",
   "metadata": {},
   "source": [
    "## **Overview**\n",
    "In Milestone 1 you have:\n",
    "1. **Defined a deep learning problem** where AI can make a meaningful impact.\n",
    "2. **Identified three datasets** that fit your topic and justified their relevance.\n",
    "3. **Explored and visualized** the datasets to understand their structure.\n",
    "4. **Implemented a PyTorch Dataset class** to prepare data for deep learning.\n",
    "\n",
    "In Milestone 2 we will take the next step and implement a neural network baseline based on what we have learned in class! For this milestone, please use one of the datasets you picked in the last milestone. If you pick a new one, make sure to do Steps 2 - 4 again. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba4078e",
   "metadata": {},
   "source": [
    "## **Step 1: Define Your Deep Learning Problem**\n",
    "\n",
    "The first step is to be clear about what you want your model to predict. Is your goal a classification or a regression task? what are the input features and what are you prediction targets y? Make sure that you have a sensible choice of features and a sensible choice of prediction targets y in your dataloader.\n",
    "\n",
    "**Write down one paragraph of justification for how you set up your DataLoader below. If it makes sense to change the DataLoader from Milestone 1, describe what you changed and why:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bb8cc8",
   "metadata": {},
   "source": [
    "## **Step 2: Train a Neural Network in PyTorch**\n",
    "\n",
    "We learned in class how to implement and train a feed forward neural network in pytorch. You can find reference implementations [here](https://github.com/mariru/Intro2ADL/blob/main/Week5/Week5_Lab_Example.ipynb) and [here](https://www.kaggle.com/code/girlboss/mmlm2025-pytorch-lb-0-00000). Tip: Try to implement the neural network by yourself from scratch before looking at the reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d971bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# define dataloaders: make sure to have a train, validation and a test loader\n",
    "\n",
    "# define the model\n",
    "\n",
    "# define the loss function and the optimizer\n",
    "\n",
    "# train the model\n",
    "\n",
    "# test the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e90508",
   "metadata": {},
   "source": [
    "## **Step 2 continued: Try Stuff**\n",
    "\n",
    "Use your code above to try different architectures. Make sure to use early stopping! Try adding Dropout and BatchNorm, try different learning rates. How do they affect training and validation performance? \n",
    "\n",
    " **Summarize your observations in a paragraph below:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8d368c",
   "metadata": {},
   "source": [
    "## **Step 3: Hyperparameter Optimization with Optuna**\n",
    "\n",
    "As you can see, hyperparameter optimization can be tedious. In class we used [optuna](https://optuna.org/#code_examples) to automate the process. Your next task is to wrap your code from Step 2 into an objective which you can then optimize with optuna. Under the [code exaples](https://optuna.org/#code_examples) there is a tab *PyTorch* which should be helpful as it provides a minimal example on how to wrap PyTorch code inside an objective.\n",
    "\n",
    "**Important: Make sure the model is evaluated on a validation set, not the training data!!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584d1593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "# Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    pass\n",
    "\n",
    "# Create a study object\n",
    "\n",
    "# Optimize the objective function.\n",
    "\n",
    "# Print out the best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f0b007",
   "metadata": {},
   "source": [
    "## **Step 3 continued: Insights**\n",
    "\n",
    "Did you find the hyperparameter search helpful? Does it help to increase the number of trials in the optimization? Note that so far we have used the simplest version of optuna which has many nice features. Can you discover more useful features by browsing the optuna website? (Hint: try pruning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54312a3",
   "metadata": {},
   "source": [
    "## **Step 4: Final Training**\n",
    "\n",
    "Now that you have found a good hyperparameter setting the validation set is no longer needed. The last step is to combine the training and validation set into a combined training set and retrain the model under the best parameter setting found. Report your final loss on your test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bcf39c",
   "metadata": {},
   "source": [
    "## **Final Submission**\n",
    "Upload your submission for Milestone 2 to Canvas. \n",
    "Happy Deep Learning! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
