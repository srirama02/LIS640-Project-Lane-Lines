{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a83ca55",
   "metadata": {},
   "source": [
    "## Milestone 1: Problem Definition, Dataset Selection, and Data Exploration\n",
    "\n",
    "LIS 640 - Introduction to Applied Deep Learning\n",
    "\n",
    "Due 2/14/25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da321fe4",
   "metadata": {},
   "source": [
    "## **Overview**\n",
    "In this milestone, you will:\n",
    "1. **Define a deep learning problem** where AI can make a meaningful impact.\n",
    "2. **Identify three datasets** that fit your topic and justify their relevance.\n",
    "3. **Explore and visualize** the datasets to understand their structure.\n",
    "4. **Implement a PyTorch Dataset class** to prepare data for deep learning.\n",
    "\n",
    "This notebook provides an example of **fuel-efficient car usage** to illustrate what is expected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba4078e",
   "metadata": {},
   "source": [
    "## **Step 1: Define Your Deep Learning Problem**\n",
    "Write a paragraph explaining:\n",
    "- **Why your chosen topic is important.**\n",
    "- **How deep learning can help solve the problem.**\n",
    "\n",
    "### **Example Problem Statement: Fuel-Efficient Car Usage**\n",
    "*Fuel efficiency is a major factor in reducing carbon emissions and lowering fuel costs. Drivers often adopt inefficient driving patterns, wasting fuel through unnecessary acceleration, braking, or idling. A deep learning model could analyze driving behavior and suggest optimizations in real-time, helping individuals improve their fuel economy.*\n",
    "\n",
    "âž¡ **Write your problem statement below:**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bb8cc8",
   "metadata": {},
   "source": [
    "## **Step 2: Identify and Justify Three Relevant Datasets**\n",
    "Find three datasets that provide useful information for solving your problem.  \n",
    "For each dataset, include:\n",
    "1. A **short description** of what it contains.\n",
    "2. A **link to the dataset**.\n",
    "3. **Why this dataset is useful for your problem.**\n",
    "\n",
    "### **Example Datasets for Fuel Efficiency**\n",
    "\n",
    "- **Dataset 1: Vehicle Trajectory Data (NGSIM US 101 Dataset)**\n",
    "\t- Description: This dataset contains detailed vehicle trajectory data collected on a segment of the U.S. Highway 101 in Los Angeles, California. It includes precise location information of each vehicle within the study area every one-tenth of a second, capturing detailed lane-changing and car-following behaviors.\n",
    "\t- Source: [U.S. Department of Transportation - NGSIM Program](https://data.transportation.gov/stories/s/Next-Generation-Simulation-NGSIM-Open-Data/i5zb-xe34/)\n",
    "\t- Justification: Analyzing this data can help identify driving patterns that affect fuel efficiency, such as frequent lane changes or abrupt braking.\n",
    "\n",
    "- **Dataset 2: Climate & Air Quality Data**  \n",
    "  - Description: Contains CO2 emissions and climate-related metrics across different regions.\n",
    "\tâ€¢\tSource: [U.S. Historical Climatology Network](https://www.ncei.noaa.gov/products/land-based-station/us-historical-climatology-network)\n",
    "\tâ€¢\tJustification: Can correlate driving behavior with environmental impact. Provides environmental context to fuel consumption.\n",
    "\n",
    "- **Dataset 3: Automobile Dataset (UCI Machine Learning Repository)**\n",
    "  - Description: This dataset includes various characteristics of automobiles, such as engine size, horsepower, weight, and fuel consumption. It also provides information on insurance risk ratings and normalized losses in use as compared to other cars.\n",
    "  - Source: [UCI Machine Learning Repository - Automobile Dataset](https://archive.ics.uci.edu/dataset/10/automobile)\n",
    "  - Justification: The datasetâ€™s detailed vehicle specifications and performance metrics can be used to analyze how different factors influence fuel efficiency, aiding in the development of predictive models.\n",
    "\n",
    "âž¡ **Find and document three datasets for your problem below:**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e90508",
   "metadata": {},
   "source": [
    "## **Step 3: Explore and Visualize Your Data**\n",
    "Understanding the structure of your dataset is crucial. Perform the following tasks:\n",
    "1. **Summarize dataset statistics:**\n",
    "   - Number of samples\n",
    "   - Number of features\n",
    "   - Data types (numerical, categorical, text, etc.)\n",
    "   - Ranges of values (min/max)\n",
    "   - Missing values\n",
    "\n",
    "2. **Create visualizations:**\n",
    "   - Histograms: Show feature distributions.\n",
    "   - Scatter plots: Explore relationships between key variables.\n",
    "   - (Optional) PCA: Visualize high-dimensional data in 2D.\n",
    "\n",
    "### **Example Exploration Code**\n",
    "Modify this code to work with your dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb59d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset (modify with your own file)\n",
    "df = pd.read_csv(\"your_dataset.csv\")\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset Overview:\")\n",
    "print(df.info())\n",
    "\n",
    "# Show summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7af6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of numerical features\n",
    "df.hist(figsize=(12, 8))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75704179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example scatter plot of two features (modify column names as needed)\n",
    "sns.scatterplot(x=df['feature1'], y=df['feature2'])\n",
    "plt.title(\"Feature1 vs Feature2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecaca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Apply PCA for dimensionality reduction (modify as needed)\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(df.select_dtypes(include=[np.number]))\n",
    "\n",
    "# Plot PCA results\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1])\n",
    "plt.title(\"PCA Projection of Dataset\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44845598",
   "metadata": {},
   "source": [
    "For each figure that you create, add an explanation of why this is a useful figure. What does it tell about your data? Which figures do you find most interesting and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8d368c",
   "metadata": {},
   "source": [
    "## **Step 4: Implement a PyTorch Dataset Class**\n",
    "Follow [this tutorial](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) to prepare data for deep learning by creating a PyTorch Dataset class that:\n",
    "- Loads data from a CSV or another source.\n",
    "- Applies preprocessing (e.g., normalization, missing value handling).\n",
    "- Returns samples in a PyTorch-compatible format.\n",
    "\n",
    "### **Example PyTorch Dataset Implementation**\n",
    "Modify this template for your dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.features = self.data[['feature1', 'feature2']].values  # Modify features\n",
    "        self.labels = self.data['target'].values  # Modify target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "# Example usage\n",
    "dataset = CustomDataset('your_dataset.csv')\n",
    "print(len(dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bcf39c",
   "metadata": {},
   "source": [
    "## **Final Submission**\n",
    "Upload your submission for Milestone 1 to Canvas. \n",
    "Submit this notebook with:\n",
    "\n",
    "âœ… A **clear problem statement**.  \n",
    "âœ… Three **documented datasets** with justification.  \n",
    "âœ… **Exploratory analysis** with summary statistics & visualizations.  \n",
    "âœ… A **PyTorch Dataset class** for preparing data.  \n",
    "\n",
    "ðŸ“Œ Use the provided example to guide your work. Happy Deep Learning! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
