{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a83ca55",
   "metadata": {},
   "source": [
    "## Milestone 1: Problem Definition, Dataset Selection, and Data Exploration\n",
    "\n",
    "LIS 640 - Introduction to Applied Deep Learning\n",
    "\n",
    "Due 2/14/25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da321fe4",
   "metadata": {},
   "source": [
    "## **Overview**\n",
    "In this milestone, you will:\n",
    "1. **Define a deep learning problem** where AI can make a meaningful impact.\n",
    "2. **Identify three datasets** that fit your topic and justify their relevance.\n",
    "3. **Explore and visualize** the datasets to understand their structure.\n",
    "4. **Implement a PyTorch Dataset class** to prepare data for deep learning.\n",
    "\n",
    "This notebook provides an example of **fuel-efficient car usage** to illustrate what is expected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba4078e",
   "metadata": {},
   "source": [
    "## **Step 1: Define Your Deep Learning Problem**\n",
    "\n",
    "### **Lane Line Detection**\n",
    "Lane line detection is a crucial aspect of most autonomous driving systems. It involves identifying and tracking the lane markings on the road to ensure the vehicle stays within its designated lane. Accurate lane detection is essential for maintaining safe driving conditions, enabling features like lane-keeping assistance, adaptive cruise control, and autonomous navigation. However, challenges such as varying lighting conditions, occlusions (e.g., by other vehicles or debris), and poorly marked or faded lane lines can make this task complex. A deep learning model trained on annotated road images can be used to detect lane lines in real-time, providing the vehicle with the necessary information to make informed decisions and navigate safely. By improving the robustness and accuracy of lane detection systems, we can enhance the safety and reliability of autonomous vehicles, ultimately contributing to safer roads and more efficient transportation systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bb8cc8",
   "metadata": {},
   "source": [
    "## **Step 2: Identify and Justify Three Relevant Datasets**\n",
    "\n",
    "- **Dataset 1: Lane Line detection Dataset**\n",
    "\t- Description: This dataset has 100 images from German roads including annotated lane lines in each image. The dataset is diverse including curved roads.\n",
    "\t- Source: [New-Lane detection Computer Vision](https://universe.roboflow.com/maanasa-prasad/new-lane-detection)\n",
    "\t- Justification: Provides lane line data from different environments and includes curved lane lines.\n",
    "\n",
    "- **Dataset 2: Indian Roads Dataset**\n",
    "\t- Description: This dataset contains over 650 labeled lane images of various road environments, such as curves, traffic, and more. It is collected from real scenarios across multiple cities in India, and includes images with lane lines that are manually annotated with polygons.\n",
    "\t- Source: Uploaded on Roboflow\n",
    "\t- Justification: Provides lane line data from a different road driving setting, allowing us to get a better variety of data (i.e. left/right hand drive, different road markings, etc).\n",
    "\n",
    "- **Dataset 3: US Roads Dataset**\n",
    "\t- Description: This dataset contains over 100 labeled lane images from highway driving in the United States in clear conditions. It includes images with the relevant lanes and lane lines annotated with polygons.\n",
    "\t- Source: Uploaded on Roboflow\n",
    "\t- Justification: Provides lane line data from a more local and potentially more relevant setting where lane line detection might be more necessary – ADAS/hands-off cruise control and steering for long highway drives.\n",
    "\n",
    "\n",
    "\n",
    "### We also found these datasets, but have not analyzed them yet due to the size and might explore them later if possible\n",
    "- **Dataset 4: CurveLanes Dataset from Kaggle**\n",
    "\t- Description: This dataset has 150k lane images of difficult scenarios such as curves and multi-lanes in traffic. It is collected from real urban and highway scenarios in multiple cities in China. The dataset includes images with lane lines which are manually annotated with natural cubic splines. The labels include two key x, y coordinates of the lane marking.\n",
    "\t- Source: [Kaggle CurveLanes Dataset](https://www.kaggle.com/datasets/bnyadmohammed/curvelanes/data) and uploaded from [Github CurveLanes Dataset](https://github.com/SoulmateB/CurveLanes)\n",
    "\t- Justification: The dataset includes more difficult to detect lane lines in more complex and variety of scenarios\n",
    "\n",
    "- **Dataset 5: Waymo Open Dataset - Motion Dataset**\n",
    "\t- Description: This dataset has lane line data which was used internally by Waymo for their training purposes which has been open sourced. It includes lane connections, lane boundaries and lane neighbors. It provies information of multiple x, y coordinates along the lane line as labels.\n",
    "\t- Source [Waymo Open Dataset](https://github.com/waymo-research/waymo-open-dataset?tab=readme-ov-file)\n",
    "\t- Justification: This data includes detailed information on more lane line data but also includes features such as lane neighbors and lane connections.\n",
    "\n",
    "- **Dataset 6: TuSimple Lane Line Dataset**\n",
    "\t- Description: The dataset consists of 6,408 road images on US highways and includes images from different weather conditions. Dataset includes annotated lane lines.\n",
    "\t- Source [TuSimple Dataset on Kaggle](https://www.kaggle.com/datasets/manideep1108/tusimple)\n",
    "\t- Justification: This dataset emphasizes variation in weather conditions which the other datasets do not mention which will allow our model to generalize better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e90508",
   "metadata": {},
   "source": [
    "## **Step 3: Explore and Visualize Your Data**\n",
    "Understanding the structure of your dataset is crucial. Perform the following tasks:\n",
    "1. **Summarize dataset statistics:**\n",
    "   - Number of samples\n",
    "   - Number of features\n",
    "   - Data types (numerical, categorical, text, etc.)\n",
    "   - Ranges of values (min/max)\n",
    "   - Missing values\n",
    "\n",
    "2. **Create visualizations:**\n",
    "   - Histograms: Show feature distributions.\n",
    "   - Scatter plots: Explore relationships between key variables.\n",
    "   - (Optional) PCA: Visualize high-dimensional data in 2D.\n",
    "\n",
    "### **Example Exploration Code**\n",
    "Modify this code to work with your dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb59d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Load dataset (modify with your own file)\n",
    "# df = pd.read_csv(\"your_dataset.csv\")\n",
    "\n",
    "# # Display basic information\n",
    "# print(\"Dataset Overview:\")\n",
    "# print(df.info())\n",
    "\n",
    "# # Show summary statistics\n",
    "# print(\"Summary Statistics:\")\n",
    "# print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e7af6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Histogram of numerical features\n",
    "# df.hist(figsize=(12, 8))\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75704179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example scatter plot of two features (modify column names as needed)\n",
    "# sns.scatterplot(x=df['feature1'], y=df['feature2'])\n",
    "# plt.title(\"Feature1 vs Feature2\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ecaca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# import numpy as np\n",
    "\n",
    "# # Apply PCA for dimensionality reduction (modify as needed)\n",
    "# pca = PCA(n_components=2)\n",
    "# X_pca = pca.fit_transform(df.select_dtypes(include=[np.number]))\n",
    "\n",
    "# # Plot PCA results\n",
    "# plt.scatter(X_pca[:, 0], X_pca[:, 1])\n",
    "# plt.title(\"PCA Projection of Dataset\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44845598",
   "metadata": {},
   "source": [
    "For each figure that you create, add an explanation of why this is a useful figure. What does it tell about your data? Which figures do you find most interesting and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8d368c",
   "metadata": {},
   "source": [
    "## **Step 4: Implement a PyTorch Dataset Class**\n",
    "Follow [this tutorial](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) to prepare data for deep learning by creating a PyTorch Dataset class that:\n",
    "- Loads data from a CSV or another source.\n",
    "- Applies preprocessing (e.g., normalization, missing value handling).\n",
    "- Returns samples in a PyTorch-compatible format.\n",
    "\n",
    "### **Example PyTorch Dataset Implementation**\n",
    "Modify this template for your dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38de410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "\n",
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, csv_file):\n",
    "#         self.data = pd.read_csv(csv_file)\n",
    "#         self.features = self.data[['feature1', 'feature2']].values  # Modify features\n",
    "#         self.labels = self.data['target'].values  # Modify target\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         x = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "#         y = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "#         return x, y\n",
    "\n",
    "# # Example usage\n",
    "# dataset = CustomDataset('your_dataset.csv')\n",
    "# print(len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81b9e4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class LaneDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_dir (str): Path to the directory with images.\n",
    "            label_dir (str): Path to the directory with lane line annotations.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = sorted(os.listdir(image_dir))\n",
    "        self.label_files = sorted(os.listdir(label_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # Ensure image is in RGB format\n",
    "\n",
    "        # Load label (from the corresponding .txt file)\n",
    "        label_path = os.path.join(self.label_dir, self.label_files[idx])\n",
    "        with open(label_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            # Parse lane line annotations\n",
    "            lanes = []\n",
    "            for line in lines:\n",
    "                # Split the line into components\n",
    "                parts = list(map(float, line.strip().split()))\n",
    "                class_id = int(parts[0])  # Class ID (e.g., 0 for lane)\n",
    "                points = parts[1:]  # Lane points (x1, y1, x2, y2, ...)\n",
    "                lanes.append((class_id, points))\n",
    "\n",
    "        # Convert to numpy arrays or tensors\n",
    "        lanes = np.array(lanes)  # Shape: (num_lanes, 1 + num_points * 2)\n",
    "\n",
    "        # Apply transformations (if any)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Return image and label\n",
    "        return image, lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.21.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy in /Users/sriramashokkumar/opt/anaconda3/envs/lis640/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.6.0 in /Users/sriramashokkumar/opt/anaconda3/envs/lis640/lib/python3.12/site-packages (from torchvision) (2.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/sriramashokkumar/opt/anaconda3/envs/lis640/lib/python3.12/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: filelock in /Users/sriramashokkumar/opt/anaconda3/envs/lis640/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/sriramashokkumar/opt/anaconda3/envs/lis640/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/sriramashokkumar/opt/anaconda3/envs/lis640/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/sriramashokkumar/opt/anaconda3/envs/lis640/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /Users/sriramashokkumar/opt/anaconda3/envs/lis640/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (2025.2.0)\n",
      "Requirement already satisfied: setuptools in /Users/sriramashokkumar/opt/anaconda3/envs/lis640/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/sriramashokkumar/opt/anaconda3/envs/lis640/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/sriramashokkumar/opt/anaconda3/envs/lis640/lib/python3.12/site-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sriramashokkumar/opt/anaconda3/envs/lis640/lib/python3.12/site-packages (from jinja2->torch==2.6.0->torchvision) (2.1.3)\n",
      "Downloading torchvision-0.21.0-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchvision\n",
      "Successfully installed torchvision-0.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install torchvision\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "# Example transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((360, 640)),  # Resize to a fixed size\n",
    "    transforms.ToTensor(),           # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bcf39c",
   "metadata": {},
   "source": [
    "## **Final Submission**\n",
    "Upload your submission for Milestone 1 to Canvas. \n",
    "Submit this notebook with:\n",
    "\n",
    "✅ A **clear problem statement**.  \n",
    "✅ Three **documented datasets** with justification.  \n",
    "✅ **Exploratory analysis** with summary statistics & visualizations.  \n",
    "✅ A **PyTorch Dataset class** for preparing data.  \n",
    "\n",
    "📌 Use the provided example to guide your work. Happy Deep Learning! 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lis640",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
